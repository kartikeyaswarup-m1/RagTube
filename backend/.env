# ===== Backend Config =====
# Vectorstore directory (FAISS index storage)
VECTORSTORE_DIR=./vectorstore

# ===== Ollama Config =====
# Model to use (make sure it's pulled: ollama pull llama3)
OLLAMA_MODEL=llama3
# Ollama server host (must match `ollama serve`)
OLLAMA_HOST=http://127.0.0.1:11434

# ===== FastAPI Config =====
# You can change the backend host/port if needed
BACKEND_HOST=127.0.0.1
BACKEND_PORT=8000